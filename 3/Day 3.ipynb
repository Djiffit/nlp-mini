{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import masc_tagged, treebank\n",
    "from nltk.tag import hmm\n",
    "%autoreload 2\n",
    "from ass3utils import train_unsupervised \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_word(words_by_tag, word):\n",
    "    if words_by_tag.get(word, False):\n",
    "        words_by_tag[word] += 1\n",
    "    else:\n",
    "        words_by_tag[word] = 1\n",
    "\n",
    "def get_counts():\n",
    "    words = {}\n",
    "    vb_transitions = {}\n",
    "    \n",
    "    for sent in masc_tagged.tagged_sents():\n",
    "        for idx, (word, tag) in enumerate(sent):\n",
    "            if words.get(tag):\n",
    "                insert_word(words[tag], word)\n",
    "            else:\n",
    "                words[tag] = {}\n",
    "                insert_word(words[tag], word)\n",
    "                \n",
    "            if tag == 'VB' and idx < (len(sent) - 1):\n",
    "                next_tag = sent[idx + 1][1]\n",
    "                if vb_transitions.get(next_tag):\n",
    "                    vb_transitions[next_tag] += 1\n",
    "                else:\n",
    "                    vb_transitions[next_tag] = 1\n",
    "                \n",
    "    return words, vb_transitions\n",
    "\n",
    "def get_probabilities(words, transitions, target, word, word_tag):\n",
    "    total_trans = sum(transitions.values())\n",
    "    trans_prob = transitions[target] / total_trans\n",
    "    \n",
    "    word_prob = words[word_tag][word] / sum(words[word_tag].values())\n",
    "    \n",
    "    print(f'Probability of VB being followed by {target} is {trans_prob * 100} %')\n",
    "    print(f'Probability of {word} within the tag {word_tag} is {word_prob * 100} %')\n",
    "    \n",
    "def tag_sents(model):\n",
    "    sents = ['Once we have finished , we will go out .',\n",
    "         'There is always room for more understanding between warring peoples .',\n",
    "         'Evidently , this was one of Jud \\'s choicest tapestries , for the noble emitted a howl of grief and rage and leaped from his divan .']\n",
    "\n",
    "    sents2 = [\n",
    "        'Misjoggle in a gripty hifnipork .',\n",
    "        'One fretigy kriptog is always better than several intersplicks .',\n",
    "        'Hello my friend can you tag some words ineptly'\n",
    "    ]\n",
    "    \n",
    "    sents3 = [\n",
    "        'Yesterday these fiends operated upon Doggo .',\n",
    "        'For a time, his own soul and this brain - maggot struggled for supremacy .'\n",
    "    ]\n",
    "    \n",
    "    sents4 = [\n",
    "        'System that prevents problems with little nephews',\n",
    "        'Trump, Angered by Investigations, Blows Up Meeting With Democrats',\n",
    "        'She Had Stage 4 Lung Cancer, and a Mountain to Climb',\n",
    "        'Business partnership agreements are written agreements which states the rights, responsibility, and accountability of the parties involved in the agreement',\n",
    "        ]\n",
    "    \n",
    "    for sent in sents:\n",
    "        print(model.tag(sent.split()), '\\n')\n",
    "    print('-' * 100)\n",
    "    for sent in sents2:\n",
    "        print(model.tag(sent.split()), '\\n')\n",
    "    print('-' * 100)\n",
    "    for sent in sents3:\n",
    "        print(model.tag(sent.split()), '\\n')\n",
    "    print('-' * 100)\n",
    "    for sent in sents4:\n",
    "        print(model.tag(sent.split()), '\\n')\n",
    "\n",
    "def log_prob(model):\n",
    "    test_sents = [\n",
    "        list(zip('Hi I am dog'.split(), [None] * 4)),\n",
    "        list(zip('Try using your models as LMs'.split(), [None] * 6)),\n",
    "        list(zip('Submit your answers'.split(), [None] * 3)),\n",
    "        list(zip('Is you are we you they us them porridge'.split(), [None] * 9)),\n",
    "        list(zip('Live computer eat slightly manic bag'.split(), [None] * 6)),\n",
    "        list(zip('I am outputting a rather probable sentence but this one is still quite long one'.split(), [None] * 15)),\n",
    "        list(zip('The the the the'.split(), [None] * 4)),\n",
    "    ]\n",
    "    \n",
    "    for sent in test_sents:\n",
    "        print(sent, 'Probability: ', model.log_probability(sent))\n",
    "        \n",
    "def sample_model(model):\n",
    "    print(model.random_sample(random, 15))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of VB being followed by DT is 19.507320241842802 %\n",
      "Probability of feel within the tag VB is 0.21406880071688159 %\n"
     ]
    }
   ],
   "source": [
    "get_probabilities(words, transitions, 'DT', 'feel', 'VB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = hmm.HiddenMarkovModelTagger\n",
    "\n",
    "model = train.train(masc_tagged.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Once', 'RB'), ('we', 'PRP'), ('have', 'VBP'), ('finished', 'VBN'), (',', ','), ('we', 'PRP'), ('will', 'MD'), ('go', 'VB'), ('out', 'RP'), ('.', '.')] \n",
      "\n",
      "[('There', 'EX'), ('is', 'VBZ'), ('always', 'RB'), ('room', 'NN'), ('for', 'IN'), ('more', 'JJR'), ('understanding', 'NN'), ('between', 'IN'), ('warring', 'VBG'), ('peoples', 'NNS'), ('.', '.')] \n",
      "\n",
      "[('Evidently', 'UH'), (',', ','), ('this', 'DT'), ('was', 'VBD'), ('one', 'CD'), ('of', 'IN'), ('Jud', 'PRP'), (\"'s\", 'VBZ'), ('choicest', 'JJ'), ('tapestries', 'NNS'), (',', ','), ('for', 'IN'), ('the', 'DT'), ('noble', 'JJ'), ('emitted', 'IN'), ('a', 'DT'), ('howl', 'NN'), ('of', 'IN'), ('grief', 'NN'), ('and', 'CC'), ('rage', 'NN'), ('and', 'CC'), ('leaped', 'VBD'), ('from', 'IN'), ('his', 'PRP$'), ('divan', 'NNS'), ('.', '.')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sents = ['Once we have finished , we will go out .',\n",
    "         'There is always room for more understanding between warring peoples .',\n",
    "         'Evidently , this was one of Jud \\'s choicest tapestries , for the noble emitted a howl of grief and rage and leaped from his divan .']\n",
    "\n",
    "for sent in sents:\n",
    "    print(model.tag(sent.split()), '\\n')\n",
    "    #Understanding should be an adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Misjoggle', 'RB'), ('in', 'IN'), ('a', 'DT'), ('gripty', 'JJ'), ('hifnipork', 'NNS'), ('.', '.')] \n",
      "\n",
      "[('One', 'CD'), ('fretigy', 'NNS'), ('kriptog', 'WDT'), ('is', 'VBZ'), ('always', 'RB'), ('better', 'JJR'), ('than', 'IN'), ('several', 'JJ'), ('intersplicks', 'NNS'), ('.', '.')] \n",
      "\n",
      "[('I', 'PRP'), ('need', 'VBP'), ('my', 'PRP$'), ('stormhammer', 'NNS')] \n",
      "\n",
      "[('Hello', 'UH'), ('my', 'PRP$'), ('friend', 'NN'), ('can', 'MD'), ('you', 'PRP'), ('tag', 'VBP'), ('some', 'DT'), ('words', 'NNS'), ('ineptly', '.'), ('.', '.')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sents2 = [\n",
    "    'Misjoggle in a gripty hifnipork .',\n",
    "    'One fretigy kriptog is always better than several intersplicks .',\n",
    "    'I need my stormhammer',\n",
    "    'Hello my friend can you tag some words ineptly .'\n",
    "]\n",
    "for sent in sents2:\n",
    "    print(model.tag(sent.split()), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised training for initialization (34534 sentences)\n",
      "Unsupervised training (999 sentences) for up to 10 iterations\n",
      "iteration 0 logprob -143817.97376630787\n",
      "iteration 1 logprob -113237.1566587721\n",
      "iteration 2 logprob -109969.0380902845\n",
      "iteration 3 logprob -107323.932597381\n",
      "iteration 4 logprob -105083.54271992383\n",
      "iteration 5 logprob -103256.08729363863\n",
      "iteration 6 logprob -101949.46522053852\n",
      "iteration 7 logprob -100943.05838591327\n",
      "iteration 8 logprob -100162.11057696443\n",
      "iteration 9 logprob -99518.63027287401\n"
     ]
    }
   ],
   "source": [
    "with open('radio_planet_tokens.txt') as radio:\n",
    "    lines = radio.readlines()\n",
    "    lines = list(map(lambda x: x.rstrip('\\n').split(), lines))\n",
    "    u_model = train_unsupervised(masc_tagged.tagged_sents(), lines, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Once', 'RB'), ('we', 'PRP'), ('have', 'VBD'), ('finished', 'VBD'), (',', ','), ('we', 'PRP'), ('will', 'MD'), ('go', 'VBP'), ('out', 'RB'), ('.', '.')] \n",
      "\n",
      "[('There', 'NNP'), ('is', 'VBZ'), ('always', 'VBN'), ('room', 'NN'), ('for', 'IN'), ('more', 'PRP$'), ('understanding', 'NN'), ('between', 'NN'), ('warring', 'NN'), ('peoples', 'NN'), ('.', 'NN')] \n",
      "\n",
      "[('Evidently', \"''\"), (',', 'WRB'), ('this', 'PRP'), ('was', 'VBD'), ('one', 'CD'), ('of', 'IN'), ('Jud', 'NNP'), (\"'s\", 'NN'), ('choicest', 'NN'), ('tapestries', 'NN'), (',', 'NN'), ('for', 'NN'), ('the', 'NN'), ('noble', 'NN'), ('emitted', 'NN'), ('a', 'NN'), ('howl', 'NN'), ('of', 'NN'), ('grief', 'NN'), ('and', 'NN'), ('rage', 'NN'), ('and', 'NN'), ('leaped', 'NN'), ('from', 'NN'), ('his', 'NN'), ('divan', 'NN'), ('.', 'NN')] \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[('Misjoggle', 'NN'), ('in', 'NN'), ('a', 'NN'), ('gripty', 'NN'), ('hifnipork', 'NN'), ('.', 'NN')] \n",
      "\n",
      "[('One', 'NNP'), ('fretigy', 'NN'), ('kriptog', 'NN'), ('is', 'NN'), ('always', 'NN'), ('better', 'NN'), ('than', 'NN'), ('several', 'NN'), ('intersplicks', 'NN'), ('.', 'NN')] \n",
      "\n",
      "[('Hello', 'NN'), ('my', 'NN'), ('friend', 'NN'), ('can', 'NN'), ('you', 'NN'), ('tag', 'NN'), ('some', 'NN'), ('words', 'NN'), ('ineptly', 'NN')] \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[('Yesterday', 'NN'), ('these', 'NN'), ('fiends', 'NN'), ('operated', 'NN'), ('upon', 'NN'), ('Doggo', 'NN'), ('.', 'NN')] \n",
      "\n",
      "[('For', \"''\"), ('a', 'DT'), ('time,', 'NN'), ('his', 'NN'), ('own', 'NN'), ('soul', 'NN'), ('and', 'NN'), ('this', 'NN'), ('brain', 'NN'), ('-', 'NN'), ('maggot', 'NN'), ('struggled', 'NN'), ('for', 'NN'), ('supremacy', 'NN'), ('.', 'NN')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tag_sents(u_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('she', 'PRP'), ('want', 'VBP'), ('like', 'IN'), ('it', 'PRP'), ('stabilize', 'VB'), ('of', 'IN'), ('lines', 'NNS'), ('attend', 'VBP'), ('to', 'TO'), ('enter', 'VB'), ('separates', 'JJ'), ('teabagging', 'VBG'), ('Wind', 'NNP'), ('America', 'NNP'), ('Uncle', 'NNP')]\n",
      "W-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-W\n",
      "[('Jud', 'NNP'), ('Arkilu', '...'), ('Formis', ')'), ('but', 'CC'), ('Doggo', 'EX'), ('slowly', 'VBD'), ('the', 'DT'), ('last', 'RBS'), ('kept', 'VBN'), ('gave', 'IN'), ('too', 'RB'), ('an', 'DT'), ('supporters', 'JJS'), ('in', 'IN'), ('her', 'PRP$')]\n",
      "W-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-WW-W\n"
     ]
    }
   ],
   "source": [
    "models = [model, u_model]\n",
    "\n",
    "for m in models:\n",
    "#     tag_sents(m)\n",
    "#     log_prob(m)\n",
    "    sample_model(m)\n",
    "    print('W-W' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
